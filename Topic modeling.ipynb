{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling and Document Clustering in NLTK and Gensim\n",
    "\n",
    "\n",
    "This project has two sections. The first section develops an algorithm to find similar documents in a document dataset, using `WordNet` and `path_similarity`. The second section develops a topic modeling algorithm. It uses Gensim's LDA (Latent Dirichlet Allocation) to identify 10 topics in a text dataset and the model is used to label new text documents. \n",
    "\n",
    "\n",
    "This project is part of Applied Data Science with Python Specialization program at the University of Michigan. The program available from [here](https://www.coursera.org/learn/python-text-mining) and [here](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) . This code is only uploaded for educational purposes and it should not be used for submitting any homework or assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Similarity\n",
    "\n",
    "This section develops a set of functions that calculates the similarity between two documents by path_similarity and pos_tag. I use `convert_tag` function to convert nltk.pos_tag to the tag used by wordnet.synsets. Then, `doc_to_synsets` function extracts synsets, and `similarity_score` function calculates the maximum similarity between synsets by path_similarity. These two functions are used by `document_path_similarity` to find the path similarity between two documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Sertab\n",
      "[nltk_data]     Gamma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Sertab Gamma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Sertab\n",
      "[nltk_data]     Gamma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "def convert_tag(tag):\n",
    "    \n",
    "    tag_dict = {'N': 'n', 'J': 'a', 'R': 'r', 'V': 'v'}\n",
    "    try:\n",
    "        return tag_dict[tag[0]]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def doc_to_synsets(doc):\n",
    "    \n",
    "    tokenized = nltk.word_tokenize(doc)\n",
    "    pos_list = nltk.pos_tag(tokenized)\n",
    "    list_of_synsets = []\n",
    "    for tag in pos_list:\n",
    "        wordnet_tag = convert_tag(tag[1])\n",
    "        synset = wn.synsets(tag[0], wordnet_tag)\n",
    "        if synset:\n",
    "            list_of_synsets.append(synset[0])   \n",
    "    return list_of_synsets\n",
    "\n",
    "\n",
    "def similarity_score(s1, s2):\n",
    "    \n",
    "    synset_list = []\n",
    "    for synset1 in s1:\n",
    "        synset_1_list = []\n",
    "        for synset2 in s2:\n",
    "            t = synset1.path_similarity(synset2)\n",
    "            if isinstance(t, float):\n",
    "                synset_1_list.append(t)\n",
    "        if synset_1_list:\n",
    "            synset_list.append(max(synset_1_list))            \n",
    "    return sum(synset_list)/len(synset_list)\n",
    "\n",
    "def document_path_similarity(doc1, doc2):\n",
    "\n",
    "    synsets1 = doc_to_synsets(doc1)\n",
    "    synsets2 = doc_to_synsets(doc2)\n",
    "    return (similarity_score(synsets1, synsets2) + similarity_score(synsets2, synsets1)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing similarity\n",
    "\n",
    "Use this function calculates similarity score between doc1 and doc2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.554265873015873"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_document_path_similarity(doc1, doc2):\n",
    "    return document_path_similarity(doc1, doc2)\n",
    "doc1 = 'This is a function to test document_path_similarity.'\n",
    "doc2 = 'Use this function to see if your code in doc_to_synsets \\\n",
    "        and similarity_score is correct!'\n",
    "test_document_path_similarity(doc1, doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "`paraphrases` is a DataFrame which is provided with this repository. It contains the following columns: `Quality`, `D1`, and `D2`.\n",
    "\n",
    "`Quality` is an indicator variable which indicates if the two documents `D1` and `D2` are paraphrases of one another (1 for paraphrase, 0 for not paraphrase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quality</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ms Stewart, the chief executive, was not expec...</td>\n",
       "      <td>Ms Stewart, 61, its chief executive officer an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>After more than two years' detention under the...</td>\n",
       "      <td>After more than two years in detention by the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>\"It still remains to be seen whether the reven...</td>\n",
       "      <td>\"It remains to be seen whether the revenue rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>And it's going to be a wild ride,\" said Allan ...</td>\n",
       "      <td>Now the rest is just mechanical,\" said Allan H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The cards are issued by Mexico's consulates to...</td>\n",
       "      <td>The card is issued by Mexico's consulates to i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quality                                                 D1  \\\n",
       "0        1  Ms Stewart, the chief executive, was not expec...   \n",
       "1        1  After more than two years' detention under the...   \n",
       "2        1  \"It still remains to be seen whether the reven...   \n",
       "3        0  And it's going to be a wild ride,\" said Allan ...   \n",
       "4        1  The cards are issued by Mexico's consulates to...   \n",
       "\n",
       "                                                  D2  \n",
       "0  Ms Stewart, 61, its chief executive officer an...  \n",
       "1  After more than two years in detention by the ...  \n",
       "2  \"It remains to be seen whether the revenue rec...  \n",
       "3  Now the rest is just mechanical,\" said Allan H...  \n",
       "4  The card is issued by Mexico's consulates to i...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrases = pd.read_csv('paraphrases.csv')\n",
    "paraphrases.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Find the most similar documents\n",
    "\n",
    "Function `document_path_similarity` is coded to find which pair of documents has the maximum similarity score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"Indeed, Iran should be put on notice that efforts to try to remake Iraq in their image will be aggressively put down,\" he said.',\n",
       " '\"Iran should be on notice that attempts to remake Iraq in Iran\\'s image will be aggressively put down,\" he said.\\n',\n",
       " 0.9753086419753086)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_similar_docs():\n",
    "    \n",
    "    similarity_score_list = []\n",
    "    for _, row in paraphrases.iterrows():\n",
    "        similarity_score_list.append(document_path_similarity(row['D1'], row['D2']))\n",
    "    similarity_score_list = np.array(similarity_score_list)\n",
    "    t = np.argmax(similarity_score_list)\n",
    "    return (paraphrases['D1'].iloc[t], paraphrases['D2'].iloc[t], similarity_score_list[t])\n",
    "\n",
    "most_similar_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare document_path_similarity function with labels\n",
    "\n",
    "`label_accuracy` function comapres perfromance of our labaling function (i.e., `document_path_similarity`) with the labels provided in paraphrases. We consider the scores greater than 0.75 as paraphrase (1), and the rest as not paraphrase (0). Finally, accuracy of the classifier is reported using scikit-learn's accuracy_score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_accuracy():\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    similarity_score_list = []\n",
    "    for _, row in paraphrases.iterrows():\n",
    "        similarity_score_list.append(document_path_similarity(row['D1'], row['D2']))\n",
    "    similarity_score_list = [1 if i>0.75 else 0 for i in similarity_score_list]\n",
    "    return accuracy_score(paraphrases['Quality'],similarity_score_list)\n",
    "\n",
    "label_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "## Topic Modelling\n",
    "\n",
    "This section uses Gensim's LDA (Latent Dirichlet Allocation) model to model topics in `newsgroup_data`. First, I use gensim.models.ldamodel.LdaModel to estimate LDA model parameters on the corpus. Then, I create `ldamodel`model with `10 topics`,`passes=25`, and `random_state=34`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "with open('newsgroups', 'rb') as f:\n",
    "    newsgroup_data = pickle.load(f)\n",
    "\n",
    "vect = CountVectorizer(min_df=20, max_df=0.2, stop_words='english', \n",
    "                       token_pattern='(?u)\\\\b\\\\w\\\\w\\\\w+\\\\b')\n",
    "X = vect.fit_transform(newsgroup_data)\n",
    "corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)\n",
    "id_map = dict((v, k) for k, v in vect.vocabulary_.items())\n",
    "\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics =10, id2word =id_map, passes=25, random_state=34)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I Using `ldamodel` model to find a list of the 10 topics and their 10 most important words in each topic. This function uses `print_topics` to extract the topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.056*\"edu\" + 0.043*\"com\" + 0.033*\"thanks\" + 0.022*\"mail\" + 0.021*\"know\" + 0.020*\"does\" + 0.014*\"info\" + 0.012*\"monitor\" + 0.010*\"looking\" + 0.010*\"don\"'),\n",
       " (1,\n",
       "  '0.024*\"ground\" + 0.018*\"current\" + 0.018*\"just\" + 0.013*\"want\" + 0.013*\"use\" + 0.011*\"using\" + 0.011*\"used\" + 0.010*\"power\" + 0.010*\"speed\" + 0.010*\"output\"'),\n",
       " (2,\n",
       "  '0.061*\"drive\" + 0.042*\"disk\" + 0.033*\"scsi\" + 0.030*\"drives\" + 0.028*\"hard\" + 0.028*\"controller\" + 0.027*\"card\" + 0.020*\"rom\" + 0.018*\"floppy\" + 0.017*\"bus\"'),\n",
       " (3,\n",
       "  '0.023*\"time\" + 0.015*\"atheism\" + 0.014*\"list\" + 0.013*\"left\" + 0.012*\"alt\" + 0.012*\"faq\" + 0.012*\"probably\" + 0.011*\"know\" + 0.011*\"send\" + 0.010*\"months\"'),\n",
       " (4,\n",
       "  '0.025*\"car\" + 0.016*\"just\" + 0.014*\"don\" + 0.014*\"bike\" + 0.012*\"good\" + 0.011*\"new\" + 0.011*\"think\" + 0.010*\"year\" + 0.010*\"cars\" + 0.010*\"time\"'),\n",
       " (5,\n",
       "  '0.030*\"game\" + 0.027*\"team\" + 0.023*\"year\" + 0.017*\"games\" + 0.016*\"play\" + 0.012*\"season\" + 0.012*\"players\" + 0.012*\"win\" + 0.011*\"hockey\" + 0.011*\"good\"'),\n",
       " (6,\n",
       "  '0.017*\"information\" + 0.014*\"help\" + 0.014*\"medical\" + 0.012*\"new\" + 0.012*\"use\" + 0.012*\"000\" + 0.012*\"research\" + 0.011*\"university\" + 0.010*\"number\" + 0.010*\"program\"'),\n",
       " (7,\n",
       "  '0.022*\"don\" + 0.021*\"people\" + 0.018*\"think\" + 0.017*\"just\" + 0.012*\"say\" + 0.011*\"know\" + 0.011*\"does\" + 0.011*\"good\" + 0.010*\"god\" + 0.009*\"way\"'),\n",
       " (8,\n",
       "  '0.034*\"use\" + 0.023*\"apple\" + 0.020*\"power\" + 0.016*\"time\" + 0.015*\"data\" + 0.015*\"software\" + 0.012*\"pin\" + 0.012*\"memory\" + 0.012*\"simms\" + 0.011*\"port\"'),\n",
       " (9,\n",
       "  '0.068*\"space\" + 0.036*\"nasa\" + 0.021*\"science\" + 0.020*\"edu\" + 0.019*\"data\" + 0.017*\"shuttle\" + 0.015*\"launch\" + 0.015*\"available\" + 0.014*\"center\" + 0.014*\"sci\"')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lda_topics():\n",
    "    \n",
    "    return ldamodel.print_topics(num_topics =10, num_words =10)\n",
    "\n",
    "lda_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a new document\n",
    "\n",
    "Now, we can use `ldamodel` model to cluster some new documents (e.g., `new_doc`). `topic_distribution` function reads the new document, vectorizes it, and converts the sparse matrix to gensim corpus. It returns a list which shows the probability of belonging to each topic. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = [\"\\n\\nIt's my understanding that the freezing will start to occur because \\\n",
    "of the\\ngrowing distance of Pluto and Charon from the Sun, due to it's\\nelliptical orbit. \\\n",
    "It is not due to shadowing effects. \\n\\n\\nPluto can shadow Charon, and vice-versa.\\n\\nGeorge \\\n",
    "Krumins\\n-- \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.020003108),\n",
       " (1, 0.020003324),\n",
       " (2, 0.020001281),\n",
       " (3, 0.4967472),\n",
       " (4, 0.020004038),\n",
       " (5, 0.020004129),\n",
       " (6, 0.020002972),\n",
       " (7, 0.020002645),\n",
       " (8, 0.020003129),\n",
       " (9, 0.34322822)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def topic_distribution():\n",
    "    \n",
    "    test_x = vect.transform(new_doc)\n",
    "    test_corpus = gensim.matutils.Sparse2Corpus(test_x, documents_columns=False)\n",
    "    return list(ldamodel[test_corpus])[0]\n",
    "\n",
    "topic_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "2qbcK",
   "launcher_item_id": "pi9Sh",
   "part_id": "kQiwX"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
